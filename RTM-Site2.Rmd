---
title: "Analysis-RTS"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
```

# Analysis Mt Rainier

I analyze the Mt Rainier data to see if the sites are warming at the same pace or not. My hypothesis is that there would be warming across the mountain, but some sites would be more buffered than the other.

Several studies have shown that anthrogrenic impacts have evidenced as regions warming(cite). The melting of ice in Arctic to the increase in CO2(cite) are some of the prominent studies affirming the impacts. Although many studies show the perils, there are many who have assesed the conservation efforts to help preserve what is left(cite).

Mt Rainier was an important choice, as montanes hold some of the worlds preserved biodiversity.

```{r ,echo=FALSE,include=FALSE}

```

```{r, echo=FALSE,include=FALSE}

```

```{r,echo=FALSE,include=FALSE}
onest <- read.csv("data/AM16-A2_hourly.csv")
onest$dt <- strptime(onest$DATE, format = "%Y-%m-%d %H:%M:%S")
str(onest)
### define function to do filtering ...

filter.with.padding <- function(x,the.filter,iter=1)
{
    q <- (length(the.filter)-1)/2
    n <- length(x)
    w <- stats::filter(c(rep(x[1],q),x,rep(x[n],q)),the.filter)[(q+1):(q+n)]
    if(iter > 1) for(i in 2:iter) w <- filter(c(rep(w[1],q),w,rep(w[n],q)),the.filter)[(q+1):(q+n)]
    return(w)
}

plot.ACFest <- function(ts, main=NULL, n.lags=40)
{
    ts.acf <- acf(ts, lag.max=n.lags, plot=FALSE)
    n.ts <- length(ts)
    xs <- 1:n.lags
    ys <- ts.acf$acf[2:(n.lags+1)]
    plot(xs,ys,typ="h",xlab="h  (lag)",ylab="ACF",ylim=c(-1,1),col="blue",main=main)
    points(xs,ys,col="red",cex=0.5)
    xs <- 1:n.lags
    xs[1] <- xs[1] - 0.25
    xs[n.lags] <- xs[n.lags] + 0.25
    lines(xs,1.96*sqrt(n.ts-xs)/n.ts,col="magenta",lty="dashed")
    lines(xs,-1.96*sqrt(n.ts-xs)/n.ts,col="magenta",lty="dashed")
    abline(h=0,lty="dashed")
    CI.hw <- 1.96/sqrt(n.ts)
    lines(c(0.75,n.lags+0.25),rep(CI.hw,2),col="blue",lty="dashed")
    lines(c(0.75,n.lags+0.25),rep(-CI.hw,2),col="blue",lty="dashed")
    return(ts.acf$acf)
}
### overhead III-2

plot(onest$dt,onest$series_xts,col="blue",xlab="year",typ="l",
     ylab=expression(x[t]),main=expression(paste("Site AB08: A2",
                                                 " Series from MT Rainier , WA")))

```


```{r,echo=FALSE,include=TRUE}


plot(onest$dt,onest$series_xts,col="blue",xlab="year",typ="l",
     ylab=expression(x[t]),main=expression(paste("Site AB08: A2",
                                                 " Series from MT Rainier , WA")))

```
# Seasonal component taken out

Use a smoothing filter to take the seasonal component out

```{r,echo=FALSE,include=FALSE}
onest$year <- substring(as.character(onest$DATE),1,4)

onest%>% select(c('DATE','series_xts','year')) %>% group_by(year) %>% summarise(months=n())

```

```{r,echo=FALSE,include=TRUE}

#ggplot needs date in POSIXct
onest$dt_txn <- as.POSIXct(onest$DATE,ormat = "%Y-%m-%d %H:%M:%S")
# Add month column
# Add day column
# Add hour column
onest$month <-format(onest$dt_txn,"%m")
onest$day <- format(onest$dt_txn,"%d")
onest$hour <- format(onest$dt_txn,"%H")


#subset it to only 9 years
# Removed 1288 rows containing missing values 
oneset_9yrs <- onest %>% select(c('dt_txn','series_xts','year','month','day','hour')) %>% 
  filter(!is.na(series_xts) & year > 2008 & year < 2017) %>% as.data.frame() 



#Summarize by months
oneset_9yrs_by_month <- oneset_9yrs %>% group_by(year,month) %>% summarise(min_t=min(series_xts),max_t= min(series_xts),mean_t=mean(series_xts),rows=n()) %>% as.data.frame()

# Add key
oneset_9yrs_by_month$xaxis <- as.double(paste(oneset_9yrs_by_month$year,oneset_9yrs_by_month$month,sep = '.'))

#1 .042 
#2 .125 
#3 .208 
#4 .292 
#5 .375 
#6 .458 
#7 .542 
#8 .625 
#9 .708 
#10 .792  
#11 .875 
#12 .958 

#create new xaxis
oneset_9yrs_by_month$xaxisred <- "0"
#Redo x-axis
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="01",]$xaxisred = "042"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="02",]$xaxisred = "125"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="03",]$xaxisred = "208"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="04",]$xaxisred = "292"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="05",]$xaxisred = "375"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="06",]$xaxisred = "458"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="07",]$xaxisred = "542"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="08",]$xaxisred = "625"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="09",]$xaxisred = "708"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="10",]$xaxisred = "792"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="11",]$xaxisred = "875"
oneset_9yrs_by_month[oneset_9yrs_by_month$month=="12",]$xaxisred = "958"

oneset_9yrs_by_month$nxaxis <- as.double(paste(oneset_9yrs_by_month$year,oneset_9yrs_by_month$xaxisred,sep = '.'))

# For every year we should have 12 values

#oneset_9yrs_by_month %>% ggplot(aes(year,mean_t,color=month)) + geom_point() +xlab("Time") + ylab("Mean Temperature (deg C)")

#Applying moving average filter
m.hat.oneset <- filter.with.padding(oneset_9yrs_by_month$mean_t,c(1/24,rep(1/12,11),1/24))

#plot(oneset_9yrs_by_month$xaxis,oneset_9yrs_by_month$mean_t,col="blue",xlab="year",typ="b",
#     ylab=expression(paste(x[t]," and ", hat(m)[t]," (deg C)")),main="Monthly Temp Values",cex=0.5)
#lines(oneset_9yrs_by_month$xaxis,m.hat.oneset,col="red",lwd=2)

plot(oneset_9yrs_by_month$nxaxis,oneset_9yrs_by_month$mean_t,col="blue",xlab="year",typ="b",
     ylab=expression(paste(x[t]," and ", hat(m)[t]," (deg C)")),main="Monthly Temp Values",cex=0.5)
lines(oneset_9yrs_by_month$nxaxis,m.hat.oneset,col="red",lwd=2)
```
# Removing the trend component.


```{r,echo=FALSE,include=TRUE}

oneset.u <- oneset_9yrs_by_month$mean_t - m.hat.oneset

plot(oneset_9yrs_by_month$nxaxis,oneset.u,col="blue",xlab="year",typ="b",ylab=expression(paste(u[t]==x[t]-hat(m)[t]," (ppm)")),main="Preliminary Detrending of Climate Series",cex=0.5)
points(oneset_9yrs_by_month$nxaxis[seq(12,96,12)],oneset.u[seq(12,96,12)],pch=16,col="red",cex=0.6)



```
# Extracting for one year to show the seasonal pattern.


```{r,echo=FALSE,include=TRUE}


oneset.w.j <- rowMeans(matrix(oneset.u ,nrow=12))

plot(1:12,oneset.w.j- mean(oneset.w.j),col="blue",xlab="year",
     typ="b",ylab=expression(hat(s)[j]),
     main=expression(paste("Climate Form Estimate {",hat(s)[j],"} of Seasonal Pattern")),
     ylim=c(-9,9),cex=0.5)


```

# Deasonalized data with trend estimate



```{r,echo=FALSE,include=TRUE}

#get all the years(columns), rows(minths)
#average all the jan, feb... dec
oneset.w.j <- rowMeans(matrix(oneset.u ,nrow=12))
oneset.s.j.hat <- rep(oneset.w.j  - mean(oneset.w.j ),8)
oneset.d <- oneset_9yrs_by_month$mean_t - oneset.s.j.hat

oneset.d.reg <- lm(oneset.d  ~ oneset_9yrs_by_month$nxaxis + I(oneset_9yrs_by_month$nxaxis^2))

plot(oneset_9yrs_by_month$nxaxis,oneset.d,col="blue",xlab="year",typ="b",
     ylab=expression(paste(d[t] == x[t] - hat(s)[t]," and ", hat(m)[t]," (deg C)")),
     main=expression(paste("Deseasonalized Data {", d[t], "} and Trend Estimate {",hat(m)[t],"}")),
     cex=0.5)
lines(oneset_9yrs_by_month$nxaxis,fitted(oneset.d.reg ),col="purple",lwd=2)

```
# Residuals removed (WN ?)

```{r,echo=FALSE,include=TRUE}

plot(oneset_9yrs_by_month$nxaxis,resid(oneset.d.reg),col="blue",xlab="year",typ="b",
     ylab=expression(paste(r[t] == x[t] - hat(m)[t] - hat(s)[t]," (degC)")),
     main=expression(paste("Residuals {",r[t],"} from Removal of {", hat(m)[t],"} and {",hat(s)[t],"}")),
     cex=0.5)

```

# ACF of Residuals

5% test

```{r,echo=FALSE,include=TRUE}

phi <- plot.ACFest(resid(oneset.d.reg), 
        expression(paste("Sample ACF for {", r[t],"}")))[2]

#AR(1)
oneset.z <- resid(oneset.d.reg)[-1] - phi*resid(oneset.d.reg)[-length(resid(oneset.d.reg))] 

isAboveThreshold <- function(X) 
   { X[ ifelse(X > 0.20  , TRUE,FALSE)]
}
isBelowThreshold <- function(X) 
   { X[ ifelse(X < -0.20  , TRUE,FALSE)]
}

```

# PACF of Residuals

```{r,echo=FALSE,include=TRUE}

ss.pacf <- acf(resid(oneset.d.reg) , lag.max=40, type="partial", plot=FALSE)
xs <- 1:40
ys <- ss.pacf$acf[1:40]
plot(xs,ys,typ="h",xlab="h  (lag)",ylab="PACF",ylim=c(-1,1),col="blue",main="Sample PACF")
points(xs,ys,col="red",cex=0.5)
n.ss <- length(oneset.z )
CI.hw <- 1.96/sqrt(n.ss)
abline(h=0,lty="dashed")
abline(h=c(-CI.hw,CI.hw),col="blue",lty="dashed")

```




# Comparison when not deasonalized
```{r,echo=FALSE,include=TRUE}
par(mfrow=c(1,2))
plot.ACFest(oneset_9yrs_by_month$mean_t, expression(paste("Sample ACF-Raw {", z[t],"}")))[2]
abline(h=0)

ss.pacf <- acf(oneset_9yrs_by_month$mean_t, lag.max=40, type="partial", plot=FALSE)
xs <- 1:40
ys <- ss.pacf$acf[1:40]
plot(xs,ys,typ="h",xlab="h  (lag)",ylab="PACF",ylim=c(-1,1),col="blue",main="Sample PACF-Raw")
points(xs,ys,col="red",cex=0.5)
n.ss <- length(oneset_9yrs_by_month$mean_t)
CI.hw <- 1.96/sqrt(n.ss)
abline(h=0,lty="dashed")
abline(h=c(-CI.hw,CI.hw),col="blue",lty="dashed")


```



#lets just analyze deseasonalized PACF and ACF  (calendar year)

```{r,echo=FALSE,include=TRUE}
par(mfrow=c(1,2))
plot.ACFest(m.hat.oneset, expression(paste("SACF-Desea {", z[t],"}")))[2]
abline(h=0)

ss.pacf <- acf(m.hat.oneset, lag.max=40, type="partial", plot=FALSE)
xs <- 1:40
ys <- ss.pacf$acf[1:40]
plot(xs,ys,typ="h",xlab="h  (lag)",ylab="PACF",ylim=c(-1,1),col="blue",main="SPACF - Desea")
points(xs,ys,col="red",cex=0.5)
n.ss <- length(m.hat.oneset)
CI.hw <- 1.96/sqrt(n.ss)
abline(h=0,lty="dashed")
abline(h=c(-CI.hw,CI.hw),col="blue",lty="dashed")


```






# Inspect the ACF and PACF of the deseasonalized/detrended series

```{r,echo=FALSE,include=TRUE}
par(mfrow=c(1,2))
plot.ACFest(resid(oneset.d.reg) , expression(paste("Sample ACF {", z[t],"}")))[2]
abline(h=0)

ss.pacf <- acf(resid(oneset.d.reg) , lag.max=40, type="partial", plot=FALSE)
xs <- 1:40
ys <- ss.pacf$acf[1:40]
plot(xs,ys,typ="h",xlab="h  (lag)",ylab="PACF",ylim=c(-1,1),col="blue",main="Sample PACF")
points(xs,ys,col="red",cex=0.5)
n.ss <- length(oneset.z )
CI.hw <- 1.96/sqrt(n.ss)
abline(h=0,lty="dashed")
abline(h=c(-CI.hw,CI.hw),col="blue",lty="dashed")


```

# Do a test of IID White Noise of the residuals
```{r,echo=FALSE,include=TRUE}
source("http://faculty.washington.edu/dbp/s519/R-code/diagnostic-tests.R")

plot.figPortmanteau <- function(Qs, quants, p=0, main=NULL)
{
    N.Qs <- length(Qs)
    hs <- (p+1):(N.Qs+p)
    plot(hs,quants,typ="n",xlab="h  (lag)",ylab=expression(paste(Q[LB],"(h) and 95% quantile")),xlim=c(0,N.Qs+p),ylim=c(0,max(c(Qs,quants))),main=main)
    points(hs,Qs,pch=16,col="blue")
    segments(seq(p+0.75,by=1,length=N.Qs),quants,seq(p+1.25,by=1,length=N.Qs),quants,lwd=2,col="red")
}
```

# Do a test of IID White Noise of detrended/deasonalized series

```{r,echo=FALSE,include=TRUE}

onoise.acf.zs <- acf(resid(oneset.d.reg), lag.max=40, plot=FALSE)$acf[-1]
Q.zs <- sapply(1:40,function(h) {portmanteau.test.LB(onoise.acf.zs[1:h],length(resid(oneset.d.reg)))})
quants.1.40 <- sapply((1:40),function(dof) {qchisq(0.05,dof,lower=FALSE)})

plot.figPortmanteau(Q.zs,quants.1.40,2,main=expression(paste("Portmanteau Test of Mt Rainier {", z[t],"}")))
```
So, fails in Portmanteau tests


# Do turning point test

```{r,echo=FALSE,include=TRUE}
results <- turning.point.test(resid(oneset.d.reg))
round(results$mu,1)
results$test.sum
round(results$p.value,3)
```

We fail to reject using turning point

# Do different sign test

```{r,echo=FALSE,include=TRUE}
results <- difference.sign.test(resid(oneset.d.reg))
round(results$mu,1)
results$test.sum
round(results$p.value,3)
```

We fail to reject using different sign test

#We next do Rank test
```{r,echo=FALSE,include=TRUE}
results <- rank.test(resid(oneset.d.reg))
round(results$mu,1)
results$P
round(results$p.value,3)
```

We fail to reject using rank test

# We next do Runs test

```{r,echo=FALSE,include=TRUE}
results <- runs.test(resid(oneset.d.reg))
round(results$mu,1)
results$n.runs
round(results$p.value,3)
```

So, fails all the tests saying that its WN

```{r,echo=FALSE,include=FALSE}
source("http://faculty.washington.edu/dbp/s519/R-code/step-down-LD-recursions.R")
source("http://faculty.washington.edu/dbp/s519/R-code/ar-coeffs-to-acvs.R")



```

# We next do  ia AICC to determine if we get any AR orders

```{r,echo=FALSE,include=TRUE}

LD.recursions <- function(acvf, p=length(acvf)-1)
  {
    blpc <- vector(mode="list", length=p)
    phis <- acvf[2]/acvf[1]
    pev  <- rep(acvf[1],p+1)
    blpc[[1]] <- phis
    pacf <- rep(phis,p)
    pev[2] <- pev[1]*(1-phis^2)
    if(p > 1)
      {
        for(k in 2:p)
          {
            old.phis <- phis
            phis <- rep(0,k)
            ## compute kth order pacf (reflection coefficient)
            phis[k] <- (acvf[k+1] - sum(old.phis*acvf[k:2]))/pev[k]
            phis[1:(k-1)] <- old.phis - phis[k]*rev(old.phis)
            blpc[[k]] <- phis
            pacf[k]  <- phis[k]
            pev[k+1] <- pev[k]*(1-phis[k]^2)
          }
      }
    structure(list(coeffs=phis,innov.var=pev[p+1],pev=pev,pacf=pacf,blpc=blpc))
  }

###
### source("http://faculty.washington.edu/dbp/s519/R-code/AICC.R")
###

AICC <- function(ts.in,ar.coeffs)
    {
        ts <- ts.in - mean(ts.in)
        n <- length(ts)
        var.ts <- sum(ts^2)/n
        p <- length(ar.coeffs)
        LD.stuff <- step.down.LD.recursions(ar.coeffs,var=var.ts)
        pacf <- rep(0,p)
        for(k in 1:p) pacf[k] <- LD.stuff$coeffs[[k]][k]
        rs <- rep(1,n)
        for(k in 1:p) rs[k] <- 1/prod(1-pacf[k:p]^2)
        ss <- ts[1]^2/rs[1]
        for(j in 2:n)
            {
                if(j < p+2) coeffs <- LD.stuff$coeffs[[j-1]]
                n.coeffs <- length(coeffs)
                ss <- ss + (ts[j] - sum(ts[(j-1):(j-n.coeffs)]*coeffs))^2/rs[j]
            }
        structure(list(AICC=n + n*log(2*pi/n) + n*log(ss) + sum(log(rs)) + 2*(p+1)*n/(n-p-2),
                       rs=rs,
                       pacf=pacf,
                       n.coeffs=n.coeffs,
                       coeffs=coeffs,
                       LD.stuff=LD.stuff))
    }

### version of AICC function that operates on ACVF ...

AICC.given.ACVF <- function(ts.in,acvf,n.parms)
  {
    ## NOTE: ASSUMES ts.in AND acvf HAVE SAME LENGTH
    ts <- ts.in - mean(ts.in)
    n <- length(ts)
    var.ts <- sum(ts^2)/n
    LD.stuff <- LD.recursions(acvf)
    pacf <- LD.stuff$pacf
    rs <- rep(1,n)
    for(k in 1:(n-1)) rs[k] <- 1/prod(1-pacf[k:(n-1)]^2)
    ss <- ts[1]^2/rs[1]
    for(j in 2:n)
      {
        coeffs <- LD.stuff$blpc[[j-1]]
        ss <- ss + (ts[j] - sum(ts[(j-1):1]*coeffs))^2/rs[j]
      }
    structure(list(AICC=n + n*log(2*pi/n) + n*log(ss) + sum(log(rs)) + 2*(n.parms+1)*n/(n-n.parms-2),
                   rs=rs,
                   pacf=pacf,
                   coeffs=coeffs,
                   LD.stuff=LD.stuff))
  }
do.it.AICC <- function(ts.in,method="yw",max.order=40)
{
    ts <- ts.in - mean(ts.in)
    n.ts <- length(ts)
    ts.var <- sum(ts^2)/n.ts
    results.wn <- AICC.given.ACVF(ts,c(ts.var,rep(0,n.ts-1)),0)$AICC
    results <- sapply(1:max.order,function(i) AICC.given.ACVF(ts,ARMAacf(ar(ts,aic=FALSE,order.max=i,method=method)$ar,lag=n.ts-1)*ts.var,i)$AICC)
    c(results.wn,results)
}

#plot(0:40,do.it.AICC(oneset.z),main="Yule-Walker")
#plot(0:40,do.it.AICC(oneset.z,method="burg"),main="Burg")
#plot(0:40,do.it.AICC(oneset.z,method="ols"),main="OLS")
#plot(0:40,do.it.AICC(oneset.z,method="mle"),main="MLE")

```

Get the AICC
```{r,echo=TRUE,include=TRUE}
plot(0:40,do.it.AICC(resid(oneset.d.reg)),main="Yule-Walker")
plot(0:40,do.it.AICC(resid(oneset.d.reg),method="burg"),main="Burg")
plot(0:40,do.it.AICC(resid(oneset.d.reg),method="ols"),main="OLS")
plot(0:40,do.it.AICC(resid(oneset.d.reg),method="mle"),main="MLE")
```

Determine orders

```{r,echo=TRUE,include=TRUE}
ar(resid(oneset.d.reg),method="yw")$order
ar(resid(oneset.d.reg),method="burg")$order
ar(resid(oneset.d.reg),method="ols")$order  # 2(?!)
ar(resid(oneset.d.reg),method="mle")$order
```
All say AR(2), and AICC concurs




# Do a test of IID White Noise of AR(1)

```{r,echo=FALSE,include=TRUE}

onoise.acf.zs <- acf(oneset.z, lag.max=40, plot=FALSE)$acf[-1]
Q.zs <- sapply(1:40,function(h) {portmanteau.test.LB(onoise.acf.zs[1:h],length(oneset.z))})
quants.1.40 <- sapply((1:40),function(dof) {qchisq(0.05,dof,lower=FALSE)})

plot.figPortmanteau(Q.zs,quants.1.40,2,main=expression(paste("Portmanteau Test of Mt Rainier {", z[t],"}")))
```

# Do turning point test

```{r,echo=FALSE,include=TRUE}
results <- turning.point.test(oneset.z)
round(results$mu,1)
results$test.sum
round(results$p.value,3)
```

We fail to reject using turning point

# Do different sign test

```{r,echo=FALSE,include=TRUE}
results <- difference.sign.test(oneset.z)
round(results$mu,1)
results$test.sum
round(results$p.value,3)
```

We fail to reject using different sign test

#We next do Rank test
```{r,echo=FALSE,include=TRUE}
results <- rank.test(oneset.z)
round(results$mu,1)
results$P
round(results$p.value,3)
```

We fail to reject using rank test

# We next do Runs test

```{r,echo=FALSE,include=TRUE}
results <- runs.test(oneset.z)
round(results$mu,1)
results$n.runs
round(results$p.value,3)
```

We fail to reject using Runs test

# We next do  ia AICC to determine if we get any AR orders ( or AR(1) fitted residuals)

Determine orders

```{r,echo=TRUE,include=TRUE}
#plot(0:40,do.it.AICC(oneset.z),main="Yule-Walker")
#plot(0:40,do.it.AICC(oneset.z,method="burg"),main="Burg")
#plot(0:40,do.it.AICC(oneset.z,method="ols"),main="OLS")
#plot(0:40,do.it.AICC(oneset.z,method="mle"),main="MLE")

```

```{r,echo=TRUE,include=TRUE}
ar(oneset.z,method="yw")$order
ar(oneset.z,method="burg")$order
ar(oneset.z,method="ols")$order  # 3(?!)
ar(oneset.z,method="mle")$order
```
Confirming, YW,Burg and MLE saying its not AR, but finding orders in others




#Below doing it without detrending/desea ACF

```{r,echo=TRUE,include=TRUE}
ss.acf <- acf(oneset_9yrs_by_month$mean_t, lag.max=40, plot=FALSE)
xs <- 1:40
ys <- ss.acf$acf[2:41]
plot(xs,ys,typ="h",xlab="h  (lag)",ylab="ACF",ylim=c(-1,1),col="blue",main="Sample ACF for Mt Rainier Series")
points(xs,ys,col="red",cex=0.5)
n.ss <- length(oneset_9yrs_by_month$mean_t)
CI.hw <- 1.96/sqrt(n.ss)
abline(h=0,lty="dashed")
abline(h=c(-CI.hw,CI.hw),col="blue",lty="dashed")
xs <- 1:50
lines(xs,1.96*sqrt(n.ss-xs)/n.ss,col="magenta",lty="dashed")
lines(xs,-1.96*sqrt(n.ss-xs)/n.ss,col="magenta",lty="dashed")
```

